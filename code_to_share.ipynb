{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1307fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sksurv\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f53a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_features(X, y):\n",
    "    X = np.array(X)\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis()\n",
    "    # m = RandomSurvivalForest()\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_correlated_features(_X_, _VALUE_): \n",
    "    corr_matrix = _X_.corr(method ='spearman').abs() # 'pearson' OR 'kendall' OR 'spearman'(non linearity assumption)\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= _VALUE_)] # <---- !!!!! insert the value !!!!\n",
    "    _X_ = _X_.drop(to_drop, axis=1)\n",
    "    #print (\"High correlated features removed:\", len(to_drop), \"\\nnew training set has:\", _X_.shape[1],\"features\")\n",
    "    return _X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d366f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(_X_, _Y_):\n",
    "    scores = fit_and_score_features(_X_, _Y_)\n",
    "    a = pd.Series(scores, index=_X_.columns).sort_values(ascending=False)\n",
    "    #print(a)\n",
    "    pipe = Pipeline([('select', SelectKBest(fit_and_score_features, k=3)), ('model', CoxPHSurvivalAnalysis())])\n",
    "    # pipe = Pipeline([('select', SelectKBest(fit_and_score_features, k=3)), ('model', RandomSurvivalForest())])\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    param_grid = {'select__k': np.arange(1, 10)}\n",
    "    cv = KFold(n_splits=3, random_state=1, shuffle=True)\n",
    "    gcv = GridSearchCV(pipe, param_grid, return_train_score=True, cv=cv)\n",
    "    SS = StandardScaler().fit(_X_)\n",
    "    train_x_SS = SS.transform(_X_)\n",
    "    gcv.fit(train_x_SS, _Y_)\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "    \n",
    "    selected_features = list(a.index[0:list(gcv.best_params_.values())[0]])\n",
    "    #print(selected_features)\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_on_training_data(_X_, _Y_, _SELECTED_FEATURES_, _FOLDS_):    \n",
    "    kf = KFold(n_splits = _FOLDS_, shuffle = True, random_state = 0)\n",
    "    a = range(0,len(_X_))\n",
    "\n",
    "    # training splits\n",
    "    k_fold= [x for x in kf.split(a)]\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for i in range(0,_FOLDS_):\n",
    "        train_x_selected = (_X_.iloc[k_fold[i][0]])[_SELECTED_FEATURES_].values\n",
    "        validation_x_selected = (_X_.iloc[k_fold[i][1]])[_SELECTED_FEATURES_].values\n",
    "\n",
    "        y_train = _Y_[k_fold[i][0]]\n",
    "        y_validation = _Y_[k_fold[i][1]]\n",
    "\n",
    "        estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "        #estimator = RandomSurvivalForest()\n",
    "\n",
    "        SS = StandardScaler().fit(train_x_selected)\n",
    "        train_x_selected = SS.transform(train_x_selected)\n",
    "        validation_x_selected = SS.transform(validation_x_selected)\n",
    "\n",
    "        estimator.fit(train_x_selected, y_train)\n",
    "        result = estimator.score(validation_x_selected, y_validation)\n",
    "\n",
    "        results_list.append(result)\n",
    "\n",
    "    print(f\"C-index mean:\", np.mean(results_list))\n",
    "    print(f\"C-index standard deviation:\", np.std(results_list))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_on_testing_data(_X_training_, _Y_training_, _X_testing_, _Y_testing_, _SELECTED_FEATURES_):\n",
    "    estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "    #estimator = RandomSurvivalForest()\n",
    "    \n",
    "    SS = StandardScaler().fit(_X_training_[_SELECTED_FEATURES_])\n",
    "    train_x_selected = SS.transform(_X_training_[_SELECTED_FEATURES_])\n",
    "    test_x_selected = SS.transform(_X_testing_[_SELECTED_FEATURES_])\n",
    "\n",
    "    estimator.fit(train_x_selected, _Y_training_)\n",
    "    print(estimator.score(test_x_selected, _Y_testing_))\n",
    "    return estimator.score(test_x_selected, _Y_testing_), estimator.predict(test_x_selected), estimator, test_x_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_on_all_datasat(_X_, _Y_, _SELECTED_FEATURES_, _FOLDS_):    \n",
    "    kf = KFold(n_splits = _FOLDS_, shuffle = True, random_state = 0)\n",
    "    a = range(0,len(_X_))\n",
    "\n",
    "    # training splits\n",
    "    k_fold= [x for x in kf.split(a)]\n",
    "\n",
    "    C_index_results_list = []\n",
    "    \n",
    "    name_columns = list(_X_[_SELECTED_FEATURES_].columns) + list(_Y_.dtype.names) + ['First_TYPE_Treatment']\n",
    "    cv_dataframe = pd.DataFrame(columns = name_columns)\n",
    "\n",
    "    for i in range(0,_FOLDS_):\n",
    "        train_x_selected = (_X_.iloc[k_fold[i][0]])[_SELECTED_FEATURES_ + ['First_TYPE_Treatment']]\n",
    "        train_First_TYPE_Treatment = train_x_selected[['First_TYPE_Treatment']]\n",
    "        train_x_selected = train_x_selected[_SELECTED_FEATURES_]\n",
    "        \n",
    "        validation_x_selected = (_X_.iloc[k_fold[i][1]])[_SELECTED_FEATURES_ + ['First_TYPE_Treatment']]\n",
    "        validation_First_TYPE_Treatment = validation_x_selected[['First_TYPE_Treatment']]\n",
    "        validation_x_selected = validation_x_selected[_SELECTED_FEATURES_]\n",
    "        \n",
    "        y_train = _Y_[k_fold[i][0]]\n",
    "        y_validation = _Y_[k_fold[i][1]]\n",
    "\n",
    "        estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "        #estimator = RandomSurvivalForest()\n",
    "\n",
    "        SS = StandardScaler().fit(train_x_selected)\n",
    "        temp = SS.transform(train_x_selected)\n",
    "        train_x_selected = pd.DataFrame(temp, index = train_x_selected.index, columns = train_x_selected.columns)\n",
    "        \n",
    "        temp = SS.transform(validation_x_selected)\n",
    "        validation_x_selected = pd.DataFrame(temp, index = validation_x_selected.index, columns = validation_x_selected.columns)   \n",
    "\n",
    "        estimator.fit(train_x_selected, y_train)\n",
    "        result = estimator.score(validation_x_selected, y_validation)\n",
    "\n",
    "        C_index_results_list.append(result)\n",
    "        \n",
    "        temp_dataframe = pd.concat([validation_x_selected, pd.DataFrame(y_validation, index = validation_x_selected.index, columns = y_validation.dtype.names)], axis = 1)\n",
    "        temp_dataframe['Risk_Score'] = estimator.predict(validation_x_selected)\n",
    "        temp_dataframe = pd.merge(temp_dataframe, validation_First_TYPE_Treatment, on=\"ID\", how=\"inner\")\n",
    "        cv_dataframe = pd.concat([cv_dataframe, temp_dataframe])\n",
    "        \n",
    "\n",
    "    print(f\"C-index mean CV:\", np.mean(C_index_results_list))\n",
    "    print(f\"C-index standard deviation CV:\", np.std(C_index_results_list))\n",
    "    return C_index_results_list, cv_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ac446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_concordance_index_OS(_DATASET_):\n",
    "    return(sksurv.metrics.concordance_index_censored(_DATASET_['Censor_OS'].astype('bool'), _DATASET_['OS'].astype(float), _DATASET_['Risk_Score']))\n",
    "def CV_concordance_index_PFS(_DATASET_):\n",
    "    return(sksurv.metrics.concordance_index_censored(_DATASET_['Censor_PFS'].astype('bool'), _DATASET_['PFS'].astype(float), _DATASET_['Risk_Score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
