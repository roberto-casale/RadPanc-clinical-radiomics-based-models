{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d8c7f3",
   "metadata": {},
   "source": [
    "### INFO for functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca89721",
   "metadata": {},
   "source": [
    "The \"fit_and_score_features\" function plays a foundational role in the feature selection process by calculating scores for each feature in dataset X, utilizing the Cox Proportional Hazards model. These scores are indicative of each feature's association with the survival outcome, represented by dataset y. This function, alongside \"remove_high_correlated_features\" and \"feature_selection\", establishes a robust framework for identifying the most significant features in a dataset. The \"remove_high_correlated_features\" function further refines the feature set by eliminating features with high correlation. Subsequently, \"feature_selection\" utilizes these functions to determine the optimal subset of features using a combination of Cox model scoring and GridSearchCV.\n",
    "\n",
    "Building upon this foundation, the functions \"CV_on_training_data\", \"result_on_testing_data\", and \"CV_on_all_dataset\" extend the model's application by implementing various forms of cross-validation and testing with GradientBoostingSurvivalAnalysis. These functions are crucial for evaluating the model's performance, fitting models, making predictions, and calculating the Concordance index. They systematically use the dataset (X, Y), the selected features, and other pertinent parameters to execute necessary evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sksurv\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f53a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_features(X, y):\n",
    "    \"\"\"\n",
    "    Calculate scores for each feature in X based on its association with the survival outcome y using Cox Proportional Hazards model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (DataFrame): Feature data.\n",
    "    y (structured array): Survival outcome data with fields 'time' and 'event'.\n",
    "    \n",
    "    Returns:\n",
    "    scores (ndarray): Array of scores for each feature.\n",
    "    \"\"\"\n",
    "    # Convert the feature dataframe to a numpy array for processing\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Determine the number of features\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Initialize an array to hold the score for each feature\n",
    "    scores = np.empty(n_features)\n",
    "    \n",
    "    # Initialize the Cox Proportional Hazards model\n",
    "    m = CoxPHSurvivalAnalysis()\n",
    "    \n",
    "    # Iterate over each feature to calculate its score\n",
    "    for j in range(n_features):\n",
    "        # Extract the feature column\n",
    "        Xj = X[:, j:j+1]\n",
    "        \n",
    "        # Fit the Cox model to the feature and survival data\n",
    "        m.fit(Xj, y)\n",
    "        \n",
    "        # Store the score (e.g., concordance index) of the feature\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    \n",
    "    # Return the array of scores, one for each feature\n",
    "    return scores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_correlated_features(_X_, _VALUE_): \n",
    "    \"\"\"\n",
    "    Remove features from X that have a correlation higher than VALUE using Spearman rank correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    _X_ (DataFrame): Feature data.\n",
    "    _VALUE_ (float): Threshold for removing correlated features.\n",
    "    \n",
    "    Returns:\n",
    "    _X_ (DataFrame): Feature data with highly correlated features removed.\n",
    "    \"\"\"\n",
    "    # Calculate the Spearman correlation matrix and take the absolute value of correlations\n",
    "    corr_matrix = _X_.corr(method ='spearman').abs()\n",
    "    \n",
    "    # Find the upper triangle of the correlation matrix to avoid duplication\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Identify columns that have any correlation value above the threshold _VALUE_\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= _VALUE_)]\n",
    "    \n",
    "    # Drop the identified columns from the dataset\n",
    "    _X_ = _X_.drop(to_drop, axis=1)\n",
    "    return _X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d366f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(_X_, _Y_):\n",
    "    \"\"\"\n",
    "    Select best features from X based on their association with survival outcome Y using Cox model and GridSearch.\n",
    "    \n",
    "    Parameters:\n",
    "    _X_ (DataFrame): Feature data.\n",
    "    _Y_ (structured array): Survival outcome data.\n",
    "    \n",
    "    Returns:\n",
    "    selected_features (list): List of selected feature names.\n",
    "    \"\"\"    \n",
    "    # Calculate scores for each feature using the Cox Proportional Hazards model\n",
    "    scores = fit_and_score_features(_X_, _Y_)\n",
    "    \n",
    "    # Sort the features based on their scores in descending order\n",
    "    a = pd.Series(scores, index=_X_.columns).sort_values(ascending=False)\n",
    "    \n",
    "    # Setup a pipeline with feature selection and Cox model\n",
    "    pipe = Pipeline([('select', SelectKBest(fit_and_score_features, k=3)), ('model', CoxPHSurvivalAnalysis())])\n",
    "    \n",
    "    # Ignore warnings during GridSearch\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Define the grid search parameters\n",
    "    param_grid = {'select__k': np.arange(1, 10)}\n",
    "    cv = KFold(n_splits=3, random_state=1, shuffle=True)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    gcv = GridSearchCV(pipe, param_grid, return_train_score=True, cv=cv)\n",
    "    \n",
    "    # Standardize the feature data\n",
    "    SS = StandardScaler().fit(_X_)\n",
    "    train_x_SS = SS.transform(_X_)\n",
    "    \n",
    "    # Fit the GridSearchCV pipeline\n",
    "    gcv.fit(train_x_SS, _Y_)\n",
    "    \n",
    "    # Get the GridSearchCV results and select the best features\n",
    "    results = pd.DataFrame(gcv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    results.loc[:, ~results.columns.str.endswith(\"_time\")]\n",
    "    selected_features = list(a.index[0:list(gcv.best_params_.values())[0]])\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_on_training_data(_X_, _Y_, _SELECTED_FEATURES_, _FOLDS_):    \n",
    "    \"\"\"\n",
    "    Perform cross-validation on training data using Gradient Boosting for survival analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    _X_ (DataFrame): Feature data for training.\n",
    "    _Y_ (structured array): Survival outcome data for training.\n",
    "    _SELECTED_FEATURES_ (list): List of selected feature names.\n",
    "    _FOLDS_ (int): Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    results_list (list): List of C-index scores for each fold.\n",
    "    \"\"\"\n",
    "    # Initialize K-Fold cross-validation\n",
    "    kf = KFold(n_splits = _FOLDS_, shuffle = True, random_state = 0)\n",
    "    a = range(0,len(_X_))\n",
    "    k_fold= [x for x in kf.split(a)]\n",
    "    \n",
    "    results_list = []\n",
    "    for i in range(0,_FOLDS_):\n",
    "        # Select training and validation data for the current fold\n",
    "        train_x_selected = (_X_.iloc[k_fold[i][0]])[_SELECTED_FEATURES_].values\n",
    "        validation_x_selected = (_X_.iloc[k_fold[i][1]])[_SELECTED_FEATURES_].values\n",
    "        y_train = _Y_[k_fold[i][0]]\n",
    "        y_validation = _Y_[k_fold[i][1]]\n",
    "        \n",
    "        # Initialize the estimator with predefined parameters\n",
    "        estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "\n",
    "        # Standardize the features\n",
    "        SS = StandardScaler().fit(train_x_selected)\n",
    "        train_x_selected = SS.transform(train_x_selected)\n",
    "        validation_x_selected = SS.transform(validation_x_selected)\n",
    "        \n",
    "        # Fit the model and calculate the C-index for the current fold\n",
    "        estimator.fit(train_x_selected, y_train)\n",
    "        result = estimator.score(validation_x_selected, y_validation)\n",
    "        results_list.append(result)\n",
    "    \n",
    "    # Output the mean and standard deviation of C-index scores\n",
    "    print(f\"C-index mean:\", np.mean(results_list))\n",
    "    print(f\"C-index standard deviation:\", np.std(results_list))\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_on_testing_data(_X_training_, _Y_training_, _X_testing_, _Y_testing_, _SELECTED_FEATURES_):\n",
    "    \"\"\"\n",
    "    Evaluate the model on testing data and return the C-index score, predictions, estimator, and transformed testing features.\n",
    "    \n",
    "    Parameters:\n",
    "    _X_training_ (DataFrame): Feature data for training.\n",
    "    _Y_training_ (structured array): Survival outcome data for training.\n",
    "    _X_testing_ (DataFrame): Feature data for testing.\n",
    "    _Y_testing_ (structured array): Survival outcome data for testing.\n",
    "    _SELECTED_FEATURES_ (list): List of selected feature names.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple containing the C-index score, predictions, fitted estimator, and transformed testing features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the estimator with predefined parameters\n",
    "    estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "\n",
    "    # Standardize the training features and transform the testing features\n",
    "    SS = StandardScaler().fit(_X_training_[_SELECTED_FEATURES_])\n",
    "    train_x_selected = SS.transform(_X_training_[_SELECTED_FEATURES_])\n",
    "    test_x_selected = SS.transform(_X_testing_[_SELECTED_FEATURES_])\n",
    "    \n",
    "    # Fit the model on training data and evaluate on testing data\n",
    "    estimator.fit(train_x_selected, _Y_training_)\n",
    "    print(estimator.score(test_x_selected, _Y_testing_))\n",
    "    return estimator.score(test_x_selected, _Y_testing_), estimator.predict(test_x_selected), estimator, test_x_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_on_all_datasat(_X_, _Y_, _SELECTED_FEATURES_, _FOLDS_):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on the entire dataset using Gradient Boosting for survival analysis and return the C-index results.\n",
    "\n",
    "    Parameters:\n",
    "    _X_ (DataFrame): The entire feature dataset.\n",
    "    _Y_ (structured array): The entire survival outcome dataset.\n",
    "    _SELECTED_FEATURES_ (list): List of feature names selected for the model.\n",
    "    _FOLDS_ (int): The number of folds to use in cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    C_index_results_list (list): List of C-index results from each fold.\n",
    "    cv_dataframe (DataFrame): Compiled results from all folds including predicted risk scores and selected features.\n",
    "    \"\"\"    \n",
    "    # Initialize KFold cross-validation\n",
    "    kf = KFold(n_splits = _FOLDS_, shuffle = True, random_state = 0)\n",
    "    \n",
    "    # Generate indices for splitting data\n",
    "    a = range(0,len(_X_))\n",
    "    k_fold= [x for x in kf.split(a)]\n",
    "    \n",
    "    # Initialize list to store C-index results\n",
    "    C_index_results_list = []    \n",
    "    \n",
    "    # Prepare dataframe to store cross-validation results\n",
    "    name_columns = list(_X_[_SELECTED_FEATURES_].columns) + list(_Y_.dtype.names) + ['First_TYPE_Treatment']\n",
    "    cv_dataframe = pd.DataFrame(columns = name_columns)\n",
    "    \n",
    "    # Loop through each fold for cross-validation\n",
    "    for i in range(0,_FOLDS_):\n",
    "        # Select training and validation data for the current fold\n",
    "        train_x_selected = (_X_.iloc[k_fold[i][0]])[_SELECTED_FEATURES_ + ['First_TYPE_Treatment']]\n",
    "        train_First_TYPE_Treatment = train_x_selected[['First_TYPE_Treatment']]\n",
    "        train_x_selected = train_x_selected[_SELECTED_FEATURES_]        \n",
    "        validation_x_selected = (_X_.iloc[k_fold[i][1]])[_SELECTED_FEATURES_ + ['First_TYPE_Treatment']]\n",
    "        validation_First_TYPE_Treatment = validation_x_selected[['First_TYPE_Treatment']]\n",
    "        validation_x_selected = validation_x_selected[_SELECTED_FEATURES_]        \n",
    "        y_train = _Y_[k_fold[i][0]]\n",
    "        y_validation = _Y_[k_fold[i][1]]\n",
    "        \n",
    "        # Initialize the Gradient Boosting Survival Analysis estimator\n",
    "        estimator = GradientBoostingSurvivalAnalysis(n_estimators= 100,learning_rate = 0.001, max_depth = 4, min_samples_split=10,min_samples_leaf=2, max_features=1, random_state=0)\n",
    "        \n",
    "        # Standardize the features\n",
    "        SS = StandardScaler().fit(train_x_selected)\n",
    "        temp = SS.transform(train_x_selected)\n",
    "        train_x_selected = pd.DataFrame(temp, index = train_x_selected.index, columns = train_x_selected.columns)                \n",
    "        temp = SS.transform(validation_x_selected)\n",
    "        validation_x_selected = pd.DataFrame(temp, index = validation_x_selected.index, columns = validation_x_selected.columns)   \n",
    "        \n",
    "        # Fit the model and compute the C-index on the validation set\n",
    "        estimator.fit(train_x_selected, y_train)\n",
    "        result = estimator.score(validation_x_selected, y_validation)\n",
    "        C_index_results_list.append(result)        \n",
    "        \n",
    "        # Store the validation results and risk scores in a dataframe\n",
    "        temp_dataframe = pd.concat([validation_x_selected, pd.DataFrame(y_validation, index = validation_x_selected.index, columns = y_validation.dtype.names)], axis = 1)\n",
    "        temp_dataframe['Risk_Score'] = estimator.predict(validation_x_selected)\n",
    "        temp_dataframe = pd.merge(temp_dataframe, validation_First_TYPE_Treatment, on=\"ID\", how=\"inner\")\n",
    "        cv_dataframe = pd.concat([cv_dataframe, temp_dataframe])\n",
    "    \n",
    "    # Print the mean and standard deviation of the C-index results\n",
    "    print(f\"C-index mean CV:\", np.mean(C_index_results_list))\n",
    "    print(f\"C-index standard deviation CV:\", np.std(C_index_results_list))\n",
    "    \n",
    "    return C_index_results_list, cv_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
